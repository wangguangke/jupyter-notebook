# 机器学习中有一个问题是不可避免的，那就是划分测试集和训练集。为什么要这么做呢，当然是提高模型的泛化能力，防止出现过拟合，并且可以寻找最优调节参数。训练集用于训练模型，测试集则是对训练好的模型进行评估的数据集。通常来说，训练集和测试集是不会有交集的，常用的数据集划分方法有以下两种：留出法和k折交叉验证法

# 留出法 直接将原数据集划分为两个互斥的数据集，即训练集与测试集。sklearn直接提供给我们这样的方法，便于操作

# 参数： 1、test_size：测试集占总数据的大小，以（0.0，1.0）之间的小数表示，默认值为0.25 2、random_state：随机数种子：其实就是该组随机数的编号，在需要重复试验的时候，保证得到一组一样的随机数。比如你每次都填1，其他参数一样的情况下你得到的随机数组是一样的。但填0或不填，每次都会不一样。

import numpy as np
from sklearn.model_selection import train_test_split

#构造一个X是5行2列的二维数组，y为5个元素的列表
X, y = np.random.randint(10,size=(5,2)), list(range(5))
X

y

#将X，y划分为训练集和测试集，测试集的比例为0.3
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=23)
X_train

X_test

y_train

y_test

# k折交叉验证法（当k为样本数量时即为留一法）

# K折交叉验证，这是将数据集分成K份，所谓K折就是将数据集通过K次分割，使得所有数据既在训练集出现过，又在测试集出现过。当然，每次分割中不会有重叠，即不会有交集，相当于无放回抽样。

# 参数： 1、n_split：折叠数量，最少为2。默认为3。 2、shuffle：是否在分割之前对数据进行洗牌。默认为false 3、random_state：随即种子数。

from sklearn.model_selection import KFold
import numpy as np

#定义X，y
X = np.array([[1, 2], [3, 4], [5, 6], [7, 8]])
y = np.array([1, 2, 3, 4])
kf = KFold(n_splits=4)

#打印折叠后分别作为训练集和测试集在原数据集上的索引
for train_index, test_index in kf.split(X):
    print("TRAIN:", train_index, "TEST:", test_index)
    X_train, X_test = X[train_index], X[test_index]
    y_train, y_test = y[train_index], y[test_index]
    
# 两个方法的主要区别在于，留出法中测试集对应的模型与训练的模型相比可能具有较大差距，降低保真性，这种没有较好的解决办法，只能人工去调整正负样本的比例，保证训练集与测试集正负样本比例大致相同，常见做法是将大约2/3~4/5的样本用于训练，剩余样本留作测试。

# k折交叉验证法不受随机样本划分方式的影响，训练出来的模型与总的数据集模型很相似。缺点在于计算成本高，数据集小的话还可以，当数据规模很大时，计算时间以及成本就相当惊人了。一般来说，根据经验我们一般选择k=5或10。    